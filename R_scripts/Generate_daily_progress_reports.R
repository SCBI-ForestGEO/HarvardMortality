# Generate plots of error rates over time and other error rate analyses for
# paper as seen here
# https://github.com/SCBI-ForestGEO/continuous_integration/issues/14
library(dplyr)
library(readxl)
library(readr)
library(stringr)
library(here)
library(janitor)
library(lubridate)
library(patchwork)
library(tidyr)
library(ggplot2)



# Load quadrat info and censused stem counts --------------------------------
# Get latest FFF
latest_FFFs <- list.files(here("raw_data/FFF_excel/"), pattern = ".xlsx", full.names = T)

# Get info on all quadrats censused so far
quadrat_info <- read_xlsx(latest_FFFs, sheet = "Root", .name_repair = "minimal") %>%
  clean_names() %>%
  select(submission_id, quad, date_time, personnel, quadrat_stem_count) %>%
  mutate(
    quadrat_stem_count = as.numeric(quadrat_stem_count),
    date_time = ymd(date_time)
  )

# Get number of stems censused per day
stems_censused_per_day <- quadrat_info %>%
  group_by(date_time) %>%
  summarize(n_stems = sum(quadrat_stem_count))


# Load trace of error reports ---------------------------------------
## Field fix errors ----
field_fix_errors <- 
  "testthat/reports/trace_of_reports/require_field_fix_error_file.csv" %>% 
  read_csv() %>%
  clean_names() %>%
  distinct() %>%
  # NOTE: A large number of erroneous "duplicated_stem" errors (~1300)
  # appear to have been accidentally manually appended to the
  # cummulative log of errors
  # trace_of_reports/require_field_fix_error_file.csv in these commits:
  # https://github.com/SCBI-ForestGEO/HarvardMortality/commit/58105fc24009b7d699c1db492693ace4d57c81c0
  # https://github.com/SCBI-ForestGEO/HarvardMortality/commit/ec7630c3d23cb3cc0e0f980fffb230799fae3902
  #
  # However I'm confident this was an error because the corresponding
  # daily field fix errors report automatically generated by GitHub
  # Actions did not include these "duplicated_stem" errors:
  # https://github.com/SCBI-ForestGEO/HarvardMortality/commit/ec83b37fcf582fb0d574f52df0ae9f5177bc6f9e
  # Hence I'm manually filtering them out:
  filter(!(orig_collection_date == ymd("2021-07-15") & error_name == "duplicated_stem")) %>% 
  # Also the previous day
  filter(!(orig_collection_date == ymd("2021-07-14") & error_name == "duplicated_stem"))

# NOTE: After 2021-07-11 duplicated_stems errors were merged into field_fix_error report
quadrat_censused_duplicated_stems <- 
  "testthat/reports/trace_of_reports/quadrat_censused_duplicated_stems.csv" %>% 
  read_csv() %>%
  clean_names() %>%
  # Count any duplicates only once
  group_by(submission_id, orig_collection_date, quad_sub_quad, stem_tag) %>%
  slice(1)

field_fix_errors <- bind_rows(
  field_fix_errors,
  quadrat_censused_duplicated_stems
)

# Create main data frames for analysis
field_fix_errors <- field_fix_errors %>%
  mutate(
    quad = str_sub(quad_sub_quad, 1, 4),
    date_time = ymd(orig_collection_date)
  ) %>%
  select(error_name, surveyor_id, submission_id, date_time)

field_fix_errors_per_day <- field_fix_errors %>%
  group_by(date_time) %>%
  summarize(field_fix = n())



## Auto fix errors ----
auto_fix_errors_per_day <- 
  "testthat/reports/trace_of_reports/will_auto_fix_error_file.csv" %>% 
  read_csv() %>%
  clean_names() %>%
  distinct() %>%
  select(error_name, surveyor_id, submission_id, date_time = orig_collection_date, quad_sub_quad, stem_tag) %>%
  mutate(
    quad = str_sub(quad_sub_quad, 1, 4),
    date_time = ymd(date_time)
  ) %>%
  select(-quad_sub_quad) %>%
  # Determine level of aggregation:
  group_by(date_time) %>%
  summarize(auto_fix = n())


## Missing stems ----
quadrat_censused_missing_stems_per_day <- 
  "testthat/reports/trace_of_reports/quadrat_censused_missing_stems.csv" %>% 
  read_csv() %>%
  clean_names() %>%
  distinct() %>%
  mutate(
    quad = str_pad(quadrat, 4, "left", "0")
  ) %>%
  select(-quadrat) %>%
  left_join(quadrat_info %>% select(date_time, quad, personnel), by = "quad") %>%
  # Determine level of aggregation:
  group_by(date_time) %>%
  summarize(missing_stems = n())



# Merge all data ---------------------------------------
error_rates <-
  # Merge error reports
  field_fix_errors_per_day %>%
  left_join(auto_fix_errors_per_day, by = "date_time") %>%
  left_join(quadrat_censused_missing_stems_per_day, by = "date_time") %>%
  replace(is.na(.), 0) %>%
  pivot_longer(cols = -c(date_time), names_to = "error_type", values_to = "n_errors") %>%
  # Get error rate being sure to account for days where 0 errors occurred
  full_join(stems_censused_per_day, by = "date_time") %>%
  mutate(errors_per_stem = n_errors / n_stems) %>%
  complete(date_time, error_type) %>%
  filter(!is.na(error_type)) %>%
  replace(is.na(.), 0)



# Generate all plots ---------------------------------------
## Stems censused per day ----
census_rate_plot <- stems_censused_per_day %>%
  ggplot(aes(x = date_time, y = n_stems)) +
  geom_point() +
  geom_line() +
  labs(
    x = "Census date", y = "# of new stems censused",
    title = "Daily new stems censused"
  )


## Daily error rate ----
error_rate_plot <- error_rates %>%
  ggplot(aes(x = date_time, y = errors_per_stem, col = error_type)) +
  geom_point() +
  geom_line() +
  labs(
    x = "Census date", y = "# of errors per stem censused",
    col = "Error type",
    title = "Daily (new) error rate"
  ) +
  coord_cartesian(
    ylim = c(0, NA)
  ) +
  theme(legend.position = "bottom")

## Merge ggplots using patchwork and save ----
filename <- file.path(here("testthat"), "reports/daily_progress.png")
census_rate_plot / error_rate_plot
ggsave(filename, device = "png", width = 16 / 2, height = 18 / 2.5, units = "in", dpi = 300)


## Daily error count ----
field_fix_errors %>%
  group_by(date_time, error_name) %>%
  summarize(n_errors = n()) %>%
  ggplot(aes(x = date_time, y = n_errors)) +
  geom_line(col = "grey") +
  geom_text(aes(label = n_errors), col = "red") +
  facet_wrap(~error_name, scales = "free_y") +
  labs(
    x = "Census date", y = "# of errors",
    title = "Daily error counts"
  ) +
  coord_cartesian(
    ylim = c(0, NA)
  ) +
  theme(legend.position = "bottom")

filename <- file.path(here("testthat"), "reports/daily_field_fix_error_counts.png")
ggsave(filename, device = "png", width = 20 / 2, height = 18 / 2.5, units = "in", dpi = 300)
